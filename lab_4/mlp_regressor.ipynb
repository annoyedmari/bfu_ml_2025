{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33ebd58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For MLP model: \n",
      "MSE: 13.27786972541976, R^2: 0.8218048837693747\n",
      "\n",
      "For linear regression model: \n",
      "MSE: 21.517444231177205, R^2: 0.7112260057484934\n",
      "\n",
      "MLP model has higher accuracy.\n"
     ]
    }
   ],
   "source": [
    "# PART 1: exploring the multi-layer perceptron (MLP) for REGRESSION problems\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# for compasison: logistic regression & SVM\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Boston Housing was deleted => trying to load the data via OpenML\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "boston_housing = fetch_openml(name = 'boston', version = 1, as_frame = True)\n",
    "X = boston_housing.data\n",
    "Y = boston_housing.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
    "# MLP is sensitive to scaling\n",
    "scale = StandardScaler()\n",
    "X_train_scale = scale.fit_transform(X_train)\n",
    "X_test_scale = scale.transform(X_test)\n",
    "\n",
    "# TASK 1.1\n",
    "# MLP model\n",
    "model_MLP = MLPRegressor(hidden_layer_sizes = (100,), max_iter = 2000, random_state = 42,\n",
    "                         solver = 'adam', early_stopping = True) # relu activation, adam solver by default\n",
    "# early stopping set to true because the optimization couldn't converge\n",
    "model_MLP.fit(X_train_scale, Y_train)\n",
    "Y_predict_MLP = model_MLP.predict(X_test_scale)\n",
    "\n",
    "# MSE, R^2 metrics\n",
    "def metrics_calc(test, predict):\n",
    "    metric_MSE = mean_squared_error(test, predict)\n",
    "    metric_R2 = r2_score(test, predict)\n",
    "    #print(f'MSE: {metric_MSE}, R^2: {metric_R2}')\n",
    "    return metric_MSE, metric_R2\n",
    "\n",
    "mse_MLP, r2_MLP = metrics_calc(Y_test, Y_predict_MLP)\n",
    "print(f'For MLP model: \\nMSE: {mse_MLP}, R^2: {r2_MLP}\\n')\n",
    "\n",
    "# Comparing MLP with LinearRegression\n",
    "\n",
    "# Linear Regression\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train_scale, Y_train)\n",
    "Y_predict_linear = model_linear.predict(X_test_scale)\n",
    "\n",
    "mse_linear, r2_linear = metrics_calc(Y_test, Y_predict_linear)\n",
    "print(f'For linear regression model: \\nMSE: {mse_linear}, R^2: {r2_linear}\\n')\n",
    "\n",
    "if (r2_MLP > r2_linear): print('MLP model has higher accuracy.')\n",
    "else: print('Linear model has higher accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee44e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layers sizes: (50,), R^2: 0.8273114292466445\n",
      "Hidden layers sizes: (100, 50), R^2: 0.8059042744423947\n",
      "Hidden layers sizes: (100, 100), R^2: 0.8446599869424918\n",
      "Hidden layers sizes: (50, 50, 50), R^2: 0.8363880452507423\n",
      "Hidden layers sizes: (100, 50, 50), R^2: 0.8298365026113701\n",
      "Hidden layers sizes: (100, 100, 100), R^2: 0.8442896408669855\n",
      "Hidden layers sizes: (200, 100, 50), R^2: 0.8458063503067669\n",
      "\n",
      "Best hidden layers size: (200, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "# TASK 1.2\n",
    "parameters = [\n",
    "    (50,), (100, 50), (100, 100), (50, 50, 50), (100, 50, 50), (100, 100, 100), (200, 100, 50)\n",
    "]\n",
    "best_config = [0, (50,)]\n",
    "for parameter in parameters:\n",
    "    model = MLPRegressor(hidden_layer_sizes = parameter, max_iter = 2000, random_state = 42,\n",
    "                         solver = 'adam', early_stopping = True)\n",
    "    model.fit(X_train_scale, Y_train)\n",
    "    Y_predict = model.predict(X_test_scale)\n",
    "    metric_r2 = r2_score(Y_test, Y_predict)\n",
    "\n",
    "    if (metric_r2 > best_config[0]):\n",
    "        best_config[0] = metric_r2\n",
    "        best_config[1] = parameter\n",
    "\n",
    "    print(f'Hidden layers sizes: {parameter}, R^2: {metric_r2}')\n",
    "\n",
    "print(f'\\nBest hidden layers size: {best_config[1]}')\n",
    "\n",
    "# More hidden layers => higher accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314abd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score\n",
      "0              0.981481  1.000000  0.990654\n",
      "1              0.924528  0.980000  0.951456\n",
      "2              0.921569  1.000000  0.959184\n",
      "3              0.960784  0.907407  0.933333\n",
      "4              1.000000  0.983333  0.991597\n",
      "5              0.940299  0.954545  0.947368\n",
      "6              0.981132  0.981132  0.981132\n",
      "7              1.000000  0.981818  0.990826\n",
      "8              0.904762  0.883721  0.894118\n",
      "9              0.982143  0.932203  0.956522\n",
      "accuracy       0.961111  0.961111  0.961111\n",
      "macro avg      0.959670  0.960416  0.959619\n",
      "weighted avg   0.961763  0.961111  0.961034\n"
     ]
    }
   ],
   "source": [
    "# PART 2: exploring the multi-layer perceptron (MLP) for CLASSIFICATION problems\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas\n",
    "\n",
    "# loading data\n",
    "digits = load_digits()\n",
    "X1 = digits.data\n",
    "Y1 = digits.target\n",
    "\n",
    "X1_scale = scale.fit_transform(X1)\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1_scale, Y1, test_size = 0.3, random_state = 42)\n",
    "\n",
    "model_clf = MLPClassifier(hidden_layer_sizes = (100,), max_iter = 2000, random_state = 42,\n",
    "                         solver = 'adam', early_stopping = True)\n",
    "model_clf.fit(X1_train, Y1_train)\n",
    "Y1_predict = model_clf.predict(X1_test)\n",
    "\n",
    "# classification report: found method in metrics\n",
    "#print(classification_report(Y1_test, Y1_predict))\n",
    "\n",
    "class_report_dict = classification_report(Y1_test, Y1_predict, output_dict = True) # report as dictionary\n",
    "class_report = pandas.DataFrame(class_report_dict).transpose()\n",
    "print(class_report[['precision', 'recall', 'f1-score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
